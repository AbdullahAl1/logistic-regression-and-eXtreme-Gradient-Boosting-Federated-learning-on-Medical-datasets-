{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "pima = pd.read_csv(\"./cl2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target variable (y)\n",
    "X = pima.drop(columns='target')\n",
    "y = pima['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative cases:  373 (48.50%)\n",
      "Number of positve cases:  396 (51.50%)\n"
     ]
    }
   ],
   "source": [
    "# Number of negative and positive cases in the data\n",
    "num_obs = len(pima)\n",
    "negative = len(pima.loc[pima['target'] == 0])\n",
    "positive = len(pima.loc[pima['target'] == 1])\n",
    "print(\"Number of negative cases:  {0} ({1:2.2f}%)\".format(negative, ((1.00 * negative)/(1.0 * num_obs)) * 100))\n",
    "print(\"Number of positve cases:  {0} ({1:2.2f}%)\".format(positive, ((1.00 * positive)/(1.0 * num_obs)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split xscale\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615, 14) (154, 14)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix: \n",
      " [[79  2]\n",
      " [ 0 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        81\n",
      "           1       0.97      1.00      0.99        73\n",
      "\n",
      "    accuracy                           0.99       154\n",
      "   macro avg       0.99      0.99      0.99       154\n",
      "weighted avg       0.99      0.99      0.99       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import metrics\n",
    "xgb = XGBClassifier(objective = 'binary:logistic')\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "print()\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fafaf\\anaconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO flwr 2024-05-12 17:56:44,209 | 141506961.py:44 | Reformatting data...\n",
      "INFO flwr 2024-05-12 17:56:44,232 | grpc.py:52 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flwr 2024-05-12 17:56:44,234 | connection.py:55 | ChannelConnectivity.IDLE\n",
      "DEBUG flwr 2024-05-12 17:56:44,237 | connection.py:55 | ChannelConnectivity.READY\n",
      "INFO flwr 2024-05-12 17:56:48,060 | 141506961.py:101 | Start training at round 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidate-error:0.14935\ttrain-error:0.04878\n",
      "[1]\tvalidate-error:0.09740\ttrain-error:0.02602\n",
      "[2]\tvalidate-error:0.03247\ttrain-error:0.00813\n",
      "[3]\tvalidate-error:0.03247\ttrain-error:0.00813\n",
      "[4]\tvalidate-error:0.03247\ttrain-error:0.00488\n",
      "Confusion Matrix: \n",
      " [[79  2]\n",
      " [ 3 70]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        81\n",
      "           1       0.97      0.96      0.97        73\n",
      "\n",
      "    accuracy                           0.97       154\n",
      "   macro avg       0.97      0.97      0.97       154\n",
      "weighted avg       0.97      0.97      0.97       154\n",
      "\n",
      "Confusion Matrix: \n",
      " [[80  1]\n",
      " [ 1 72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        81\n",
      "           1       0.99      0.99      0.99        73\n",
      "\n",
      "    accuracy                           0.99       154\n",
      "   macro avg       0.99      0.99      0.99       154\n",
      "weighted avg       0.99      0.99      0.99       154\n",
      "\n",
      "Confusion Matrix: \n",
      " [[80  1]\n",
      " [ 1 72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        81\n",
      "           1       0.99      0.99      0.99        73\n",
      "\n",
      "    accuracy                           0.99       154\n",
      "   macro avg       0.99      0.99      0.99       154\n",
      "weighted avg       0.99      0.99      0.99       154\n",
      "\n",
      "Confusion Matrix: \n",
      " [[80  1]\n",
      " [ 0 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        81\n",
      "           1       0.99      1.00      0.99        73\n",
      "\n",
      "    accuracy                           0.99       154\n",
      "   macro avg       0.99      0.99      0.99       154\n",
      "weighted avg       0.99      0.99      0.99       154\n",
      "\n",
      "Confusion Matrix: \n",
      " [[80  1]\n",
      " [ 0 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        81\n",
      "           1       0.99      1.00      0.99        73\n",
      "\n",
      "    accuracy                           0.99       154\n",
      "   macro avg       0.99      0.99      0.99       154\n",
      "weighted avg       0.99      0.99      0.99       154\n",
      "\n",
      "Confusion Matrix: \n",
      " [[80  1]\n",
      " [ 0 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        81\n",
      "           1       0.99      1.00      0.99        73\n",
      "\n",
      "    accuracy                           0.99       154\n",
      "   macro avg       0.99      0.99      0.99       154\n",
      "weighted avg       0.99      0.99      0.99       154\n",
      "\n",
      "Confusion Matrix: \n",
      " [[80  1]\n",
      " [ 0 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        81\n",
      "           1       0.99      1.00      0.99        73\n",
      "\n",
      "    accuracy                           0.99       154\n",
      "   macro avg       0.99      0.99      0.99       154\n",
      "weighted avg       0.99      0.99      0.99       154\n",
      "\n",
      "Confusion Matrix: \n",
      " [[81  0]\n",
      " [ 0 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        73\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n",
      "Confusion Matrix: \n",
      " [[81  0]\n",
      " [ 0 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        73\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n",
      "Confusion Matrix: \n",
      " [[81  0]\n",
      " [ 0 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        73\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n",
      "Confusion Matrix: \n",
      " [[81  0]\n",
      " [ 0 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        73\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n",
      "Confusion Matrix: \n",
      " [[81  0]\n",
      " [ 0 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        73\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n",
      "Confusion Matrix: \n",
      " [[81  0]\n",
      " [ 0 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        73\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n",
      "Confusion Matrix: \n",
      " [[81  0]\n",
      " [ 0 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        73\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-05-12 17:56:48,723 | connection.py:220 | gRPC channel closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[81  0]\n",
      " [ 0 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        73\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n",
      "Confusion Matrix: \n",
      " [[81  0]\n",
      " [ 0 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        73\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n",
      "Confusion Matrix: \n",
      " [[81  0]\n",
      " [ 0 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        73\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n",
      "Confusion Matrix: \n",
      " [[81  0]\n",
      " [ 0 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        73\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n",
      "Confusion Matrix: \n",
      " [[81  0]\n",
      " [ 0 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        73\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n",
      "Confusion Matrix: \n",
      " [[81  0]\n",
      " [ 0 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        73\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-05-12 17:56:48,724 | app.py:398 | Disconnect and shut down\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import warnings\n",
    "from typing import Union\n",
    "from logging import INFO\n",
    "from datasets import Dataset, DatasetDict\n",
    "import xgboost as xgb\n",
    "\n",
    "import flwr as fl\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr.common.logger import log\n",
    "from flwr.common import (\n",
    "    Code,\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    GetParametersIns,\n",
    "    GetParametersRes,\n",
    "    Parameters,\n",
    "    Status,\n",
    ")\n",
    "from flwr_datasets.partitioner import IidPartitioner\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# def transform_dataset_to_dmatrix(data: Union[Dataset, DatasetDict]) -> xgb.core.DMatrix:\n",
    "#     \"\"\"Transform dataset to DMatrix format for xgboost.\"\"\"\n",
    "#     x = data[\"inputs\"]\n",
    "#     y = data[\"label\"]\n",
    "#     new_data = xgb.DMatrix(x, label=y)\n",
    "#     return new_data\n",
    "\n",
    "# # Train/test splitting\n",
    "# train_data, valid_data, num_train, num_val = X_train, X_test, y_train, y_test\n",
    "num_train = 420\n",
    "num_val = 105\n",
    "\n",
    "\n",
    "xgb_train = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
    "xgb_test = xgb.DMatrix(X_test, y_test, enable_categorical=True)\n",
    "\n",
    "# Reformat data to DMatrix for xgboost\n",
    "log(INFO, \"Reformatting data...\")\n",
    "# train_dmatrix = transform_dataset_to_dmatrix(train_data)\n",
    "# valid_dmatrix = transform_dataset_to_dmatrix(valid_data)\n",
    "train_dmatrix = xgb_train\n",
    "valid_dmatrix = xgb_test\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# Hyper-parameters for xgboost training\n",
    "num_local_round = 5\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eta\": 0.5,  # Learning rate\n",
    "    \"max_depth\": 25,\n",
    "    \"eval_metric\": \"error\",\n",
    "    \"nthread\": 16,\n",
    "    \"num_parallel_tree\": 1,\n",
    "    \"subsample\": 1,\n",
    "    \"tree_method\": \"hist\",\n",
    "}\n",
    "\n",
    "\n",
    "# Define Flower client\n",
    "class XgbClient(fl.client.Client):\n",
    "    def __init__(self):\n",
    "        self.bst = None\n",
    "        self.config = None\n",
    "\n",
    "    def get_parameters(self, ins: GetParametersIns) -> GetParametersRes:\n",
    "        _ = (self, ins)\n",
    "        return GetParametersRes(\n",
    "            status=Status(\n",
    "                code=Code.OK,\n",
    "                message=\"OK\",\n",
    "            ),\n",
    "            parameters=Parameters(tensor_type=\"\", tensors=[]),\n",
    "        )\n",
    "\n",
    "    def _local_boost(self):\n",
    "        # Update trees based on local training data.\n",
    "        for i in range(num_local_round):\n",
    "            self.bst.update(train_dmatrix, self.bst.num_boosted_rounds())\n",
    "\n",
    "        # Extract the last N=num_local_round trees for sever aggregation\n",
    "        bst = self.bst[\n",
    "            self.bst.num_boosted_rounds()\n",
    "            - num_local_round : self.bst.num_boosted_rounds()\n",
    "        ]\n",
    "\n",
    "        return bst\n",
    "\n",
    "    def fit(self, ins: FitIns) -> FitRes:\n",
    "        if not self.bst:\n",
    "            # First round local training\n",
    "            log(INFO, \"Start training at round 1\")\n",
    "            bst = xgb.train(\n",
    "                params,\n",
    "                train_dmatrix,\n",
    "                num_boost_round=num_local_round,\n",
    "                evals=[(valid_dmatrix, \"validate\"), (train_dmatrix, \"train\")],\n",
    "            )\n",
    "            self.config = bst.save_config()\n",
    "            self.bst = bst\n",
    "        else:\n",
    "            for item in ins.parameters.tensors:\n",
    "                global_model = bytearray(item)\n",
    "\n",
    "            # Load global model into booster\n",
    "            self.bst.load_model(global_model)\n",
    "            self.bst.load_config(self.config)\n",
    "\n",
    "            bst = self._local_boost()\n",
    "\n",
    "        local_model = bst.save_raw(\"json\")\n",
    "        local_model_bytes = bytes(local_model)\n",
    "\n",
    "        return FitRes(\n",
    "            status=Status(\n",
    "                code=Code.OK,\n",
    "                message=\"OK\",\n",
    "            ),\n",
    "            parameters=Parameters(tensor_type=\"\", tensors=[local_model_bytes]),\n",
    "            num_examples=num_train,\n",
    "            metrics={},\n",
    "        )\n",
    "\n",
    "    def evaluate(self, ins: EvaluateIns) -> EvaluateRes:\n",
    "        eval_results = self.bst.eval_set(\n",
    "            evals=[(valid_dmatrix, \"valid\")],\n",
    "            iteration=self.bst.num_boosted_rounds() - 1,\n",
    "        )\n",
    "        auc = round(float(eval_results.split(\"\\t\")[1].split(\":\")[1]), 4)\n",
    "        \n",
    "        preds = self.bst.predict(valid_dmatrix)\n",
    "        y_pred = np.multiply(preds,100)\n",
    "        y_pred = y_pred.astype(int)\n",
    "        a = [1 if i >= 50 else 0 for i in y_pred]\n",
    "        print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, a))\n",
    "        print(metrics.classification_report(y_test,a))\n",
    "        \n",
    "\n",
    "        return EvaluateRes(\n",
    "            status=Status(\n",
    "                code=Code.OK,\n",
    "                message=\"OK\",\n",
    "            ),\n",
    "            loss=0.0,\n",
    "            num_examples=num_val,\n",
    "            metrics={\"error\": auc},\n",
    "        )\n",
    "\n",
    "\n",
    "# Start Flower client\n",
    "fl.client.start_client(server_address=\"127.0.0.1:8080\", client=XgbClient().to_client())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
