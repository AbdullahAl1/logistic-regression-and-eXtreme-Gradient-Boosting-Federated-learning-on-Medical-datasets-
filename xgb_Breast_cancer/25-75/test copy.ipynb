{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-05-03 14:28:37,018 | 1621290902.py:55 | Loading partition...\n",
      "INFO flwr 2024-05-03 14:29:11,035 | 1621290902.py:65 | Reformatting data...\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import warnings\n",
    "from typing import Union\n",
    "from logging import INFO\n",
    "from datasets import Dataset, DatasetDict\n",
    "import xgboost as xgb\n",
    "\n",
    "import flwr as fl\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr.common.logger import log\n",
    "from flwr.common import (\n",
    "    Code,\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    GetParametersIns,\n",
    "    GetParametersRes,\n",
    "    Parameters,\n",
    "    Status,\n",
    ")\n",
    "from flwr_datasets.partitioner import IidPartitioner\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "# Define data partitioning related functions\n",
    "def train_test_split(partition: Dataset, test_fraction: float, seed: int):\n",
    "    \"\"\"Split the data into train and validation set given split rate.\"\"\"\n",
    "    train_test = partition.train_test_split(test_size=test_fraction, seed=seed)\n",
    "    partition_train = train_test[\"train\"]\n",
    "    partition_test = train_test[\"test\"]\n",
    "\n",
    "    num_train = len(partition_train)\n",
    "    num_test = len(partition_test)\n",
    "\n",
    "    return partition_train, partition_test, num_train, num_test\n",
    "\n",
    "\n",
    "def transform_dataset_to_dmatrix(data: Union[Dataset, DatasetDict]) -> xgb.core.DMatrix:\n",
    "    \"\"\"Transform dataset to DMatrix format for xgboost.\"\"\"\n",
    "    x = data[\"inputs\"]\n",
    "    y = data[\"label\"]\n",
    "    new_data = xgb.DMatrix(x, label=y)\n",
    "    return new_data\n",
    "\n",
    "\n",
    "# Load (HIGGS) dataset and conduct partitioning\n",
    "# We use a small subset (num_partitions=30) of the dataset for demonstration to speed up the data loading process.\n",
    "partitioner = IidPartitioner(num_partitions=30)\n",
    "fds = FederatedDataset(dataset=\"jxie/higgs\", partitioners={\"train\": partitioner})\n",
    "\n",
    "# Load the partition for this `partition_id`\n",
    "log(INFO, \"Loading partition...\")\n",
    "partition = fds.load_partition(node_id=0, split=\"train\")\n",
    "partition.set_format(\"numpy\")\n",
    "\n",
    "# Train/test splitting\n",
    "train_data, valid_data, num_train, num_val = train_test_split(\n",
    "    partition, test_fraction=0.2, seed=42\n",
    ")\n",
    "\n",
    "# Reformat data to DMatrix for xgboost\n",
    "log(INFO, \"Reformatting data...\")\n",
    "train_dmatrix = transform_dataset_to_dmatrix(train_data)\n",
    "valid_dmatrix = transform_dataset_to_dmatrix(valid_data)\n",
    "\n",
    "# Hyper-parameters for xgboost training\n",
    "num_local_round = 1\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eta\": 0.1,  # Learning rate\n",
    "    \"max_depth\": 8,\n",
    "    \"eval_metric\": \"error\",\n",
    "    \"nthread\": 16,\n",
    "    \"num_parallel_tree\": 1,\n",
    "    \"subsample\": 1,\n",
    "    \"tree_method\": \"hist\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-05-03 14:38:48,689 | grpc.py:52 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flwr 2024-05-03 14:38:48,700 | connection.py:55 | ChannelConnectivity.IDLE\n",
      "DEBUG flwr 2024-05-03 14:38:48,702 | connection.py:55 | ChannelConnectivity.CONNECTING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-05-03 14:38:50,736 | connection.py:55 | ChannelConnectivity.READY\n",
      "INFO flwr 2024-05-03 14:38:57,119 | 2029506884.py:33 | Start training at round 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidate-error:0.39006\ttrain-error:0.38980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-05-03 14:38:58,527 | connection.py:220 | gRPC channel closed\n",
      "INFO flwr 2024-05-03 14:38:58,528 | app.py:398 | Disconnect and shut down\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define Flower client\n",
    "class XgbClient(fl.client.Client):\n",
    "    def __init__(self):\n",
    "        self.bst = None\n",
    "        self.config = None\n",
    "\n",
    "    def get_parameters(self, ins: GetParametersIns) -> GetParametersRes:\n",
    "        _ = (self, ins)\n",
    "        return GetParametersRes(\n",
    "            status=Status(\n",
    "                code=Code.OK,\n",
    "                message=\"OK\",\n",
    "            ),\n",
    "            parameters=Parameters(tensor_type=\"\", tensors=[]),\n",
    "        )\n",
    "\n",
    "    def _local_boost(self):\n",
    "        # Update trees based on local training data.\n",
    "        for i in range(num_local_round):\n",
    "            self.bst.update(train_dmatrix, self.bst.num_boosted_rounds())\n",
    "\n",
    "        # Extract the last N=num_local_round trees for sever aggregation\n",
    "        bst = self.bst[\n",
    "            self.bst.num_boosted_rounds()\n",
    "            - num_local_round : self.bst.num_boosted_rounds()\n",
    "        ]\n",
    "\n",
    "        return bst\n",
    "\n",
    "    def fit(self, ins: FitIns) -> FitRes:\n",
    "        if not self.bst:\n",
    "            # First round local training\n",
    "            log(INFO, \"Start training at round 1\")\n",
    "            bst = xgb.train(\n",
    "                params,\n",
    "                train_dmatrix,\n",
    "                num_boost_round=num_local_round,\n",
    "                evals=[(valid_dmatrix, \"validate\"), (train_dmatrix, \"train\")],\n",
    "            )\n",
    "            self.config = bst.save_config()\n",
    "            self.bst = bst\n",
    "        else:\n",
    "            for item in ins.parameters.tensors:\n",
    "                global_model = bytearray(item)\n",
    "\n",
    "            # Load global model into booster\n",
    "            self.bst.load_model(global_model)\n",
    "            self.bst.load_config(self.config)\n",
    "\n",
    "            bst = self._local_boost()\n",
    "\n",
    "        local_model = bst.save_raw(\"json\")\n",
    "        local_model_bytes = bytes(local_model)\n",
    "\n",
    "        return FitRes(\n",
    "            status=Status(\n",
    "                code=Code.OK,\n",
    "                message=\"OK\",\n",
    "            ),\n",
    "            parameters=Parameters(tensor_type=\"\", tensors=[local_model_bytes]),\n",
    "            num_examples=num_train,\n",
    "            metrics={},\n",
    "        )\n",
    "\n",
    "    def evaluate(self, ins: EvaluateIns) -> EvaluateRes:\n",
    "        eval_results = self.bst.eval_set(\n",
    "            evals=[(valid_dmatrix, \"valid\")],\n",
    "            iteration=self.bst.num_boosted_rounds() - 1,\n",
    "        )\n",
    "        auc = round(float(eval_results.split(\"\\t\")[1].split(\":\")[1]), 4)\n",
    "\n",
    "        return EvaluateRes(\n",
    "            status=Status(\n",
    "                code=Code.OK,\n",
    "                message=\"OK\",\n",
    "            ),\n",
    "            loss=0.0,\n",
    "            num_examples=num_val,\n",
    "            metrics={\"AUC\": auc},\n",
    "        )\n",
    "\n",
    "\n",
    "# Start Flower client\n",
    "fl.client.start_client(server_address=\"127.0.0.1:8080\", client=XgbClient().to_client())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
