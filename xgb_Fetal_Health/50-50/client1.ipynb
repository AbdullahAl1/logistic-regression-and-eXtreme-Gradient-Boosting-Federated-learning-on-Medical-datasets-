{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"./cl1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning values to features as X and target as y\n",
    "X=data.drop([\"fetal_health\"],axis=1)\n",
    "y=data[\"fetal_health\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    734\n",
       "1    247\n",
       "2     82\n",
       "Name: fetal_health, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set: (850, 22)\n",
      "Shape of test set: (213, 22)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X,y,\n",
    "                test_size=0.2,\n",
    "                random_state=42)\n",
    "\n",
    "print(\"Shape of training set:\", X_train.shape)\n",
    "print(\"Shape of test set:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier \n",
    "\n",
    "xgb = XGBClassifier(objective = 'binary:logistic')\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "print()\n",
    "y_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[138   6   0]\n",
      " [  4  48   0]\n",
      " [  0   3  14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       144\n",
      "           1       0.84      0.92      0.88        52\n",
      "           2       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.94       213\n",
      "   macro avg       0.94      0.90      0.92       213\n",
      "weighted avg       0.94      0.94      0.94       213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn import metrics \n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-05-12 14:03:26,396 | 4151445355.py:45 | Reformatting data...\n",
      "INFO flwr 2024-05-12 14:03:26,398 | grpc.py:52 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flwr 2024-05-12 14:03:26,412 | connection.py:55 | ChannelConnectivity.IDLE\n",
      "DEBUG flwr 2024-05-12 14:03:26,415 | connection.py:55 | ChannelConnectivity.READY\n",
      "INFO flwr 2024-05-12 14:03:29,394 | 4151445355.py:95 | Start training at round 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidate-mlogloss:0.59181\ttrain-mlogloss:0.54826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-05-12 14:03:30,263 | connection.py:220 | gRPC channel closed\n",
      "INFO flwr 2024-05-12 14:03:30,264 | app.py:398 | Disconnect and shut down\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import warnings\n",
    "from typing import Union\n",
    "from logging import INFO\n",
    "from datasets import Dataset, DatasetDict\n",
    "import xgboost as xgb\n",
    "\n",
    "import flwr as fl\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr.common.logger import log\n",
    "from flwr.common import (\n",
    "    Code,\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    GetParametersIns,\n",
    "    GetParametersRes,\n",
    "    Parameters,\n",
    "    Status,\n",
    ")\n",
    "from flwr_datasets.partitioner import IidPartitioner\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import metrics \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# def transform_dataset_to_dmatrix(data: Union[Dataset, DatasetDict]) -> xgb.core.DMatrix:\n",
    "#     \"\"\"Transform dataset to DMatrix format for xgboost.\"\"\"\n",
    "#     x = data[\"inputs\"]\n",
    "#     y = data[\"label\"]\n",
    "#     new_data = xgb.DMatrix(x, label=y)\n",
    "#     return new_data\n",
    "\n",
    "# # Train/test splitting\n",
    "# train_data, valid_data, num_train, num_val = X_train, X_test, y_train, y_test\n",
    "num_train = 850\n",
    "num_val = 213\n",
    "\n",
    "\n",
    "xgb_train = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
    "xgb_test = xgb.DMatrix(X_test, y_test, enable_categorical=True)\n",
    "\n",
    "# Reformat data to DMatrix for xgboost\n",
    "log(INFO, \"Reformatting data...\")\n",
    "# train_dmatrix = transform_dataset_to_dmatrix(train_data)\n",
    "# valid_dmatrix = transform_dataset_to_dmatrix(valid_data)\n",
    "train_dmatrix = xgb_train\n",
    "valid_dmatrix = xgb_test\n",
    "\n",
    "\n",
    "# Hyper-parameters for xgboost training\n",
    "num_local_round = 1\n",
    "params = {\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"eta\": 0.5,  # Learning rate\n",
    "    \"max_depth\": 100,\n",
    "   \"eval_metric\": \"mlogloss\",\n",
    "    'num_class':3\n",
    "}\n",
    "\n",
    "\n",
    "# Define Flower client\n",
    "class XgbClient(fl.client.Client):\n",
    "    def __init__(self):\n",
    "        self.bst = None\n",
    "        self.config = None\n",
    "\n",
    "    def get_parameters(self, ins: GetParametersIns) -> GetParametersRes:\n",
    "        _ = (self, ins)\n",
    "        return GetParametersRes(\n",
    "            status=Status(\n",
    "                code=Code.OK,\n",
    "                message=\"OK\",\n",
    "            ),\n",
    "            parameters=Parameters(tensor_type=\"\", tensors=[]),\n",
    "        )\n",
    "\n",
    "    def _local_boost(self):\n",
    "        # Update trees based on local training data.\n",
    "        for i in range(num_local_round):\n",
    "            self.bst.update(train_dmatrix, self.bst.num_boosted_rounds())\n",
    "\n",
    "        # Extract the last N=num_local_round trees for sever aggregation\n",
    "        bst = self.bst[\n",
    "            self.bst.num_boosted_rounds()\n",
    "            - num_local_round : self.bst.num_boosted_rounds()\n",
    "        ]\n",
    "\n",
    "        return bst\n",
    "\n",
    "    def fit(self, ins: FitIns) -> FitRes:\n",
    "        if not self.bst:\n",
    "            # First round local training\n",
    "            log(INFO, \"Start training at round 1\")\n",
    "            bst = xgb.train(\n",
    "                params,\n",
    "                train_dmatrix,\n",
    "                num_boost_round=num_local_round,\n",
    "                evals=[(valid_dmatrix, \"validate\"), (train_dmatrix, \"train\")],\n",
    "            )\n",
    "            self.config = bst.save_config()\n",
    "            self.bst = bst\n",
    "        else:\n",
    "            for item in ins.parameters.tensors:\n",
    "                global_model = bytearray(item)\n",
    "\n",
    "            # Load global model into booster\n",
    "            self.bst.load_model(global_model)\n",
    "            self.bst.load_config(self.config)\n",
    "\n",
    "            bst = self._local_boost()\n",
    "\n",
    "        local_model = bst.save_raw(\"json\")\n",
    "        local_model_bytes = bytes(local_model)\n",
    "\n",
    "        return FitRes(\n",
    "            status=Status(\n",
    "                code=Code.OK,\n",
    "                message=\"OK\",\n",
    "            ),\n",
    "            parameters=Parameters(tensor_type=\"\", tensors=[local_model_bytes]),\n",
    "            num_examples=num_train,\n",
    "            metrics={},\n",
    "        )\n",
    "\n",
    "    def evaluate(self, ins: EvaluateIns) -> EvaluateRes:\n",
    "        eval_results = self.bst.eval_set(\n",
    "            evals=[(valid_dmatrix, \"valid\")],\n",
    "            iteration=self.bst.num_boosted_rounds() - 1,\n",
    "        )\n",
    "        auc = round(float(eval_results.split(\"\\t\")[1].split(\":\")[1]), 4)\n",
    "        \n",
    "        preds = self.bst.predict(valid_dmatrix)\n",
    "        y_pred = np.multiply(preds,100)\n",
    "        y_pred = y_pred.astype(int)\n",
    "        # a = [0 if i == 0 else 1 if i == 100 else 2 for i in y_pred]\n",
    "        # print(classification_report(y_test, a))\n",
    "        # print(metrics.classification_report(y_test,a))\n",
    "        \n",
    "\n",
    "\n",
    "        return EvaluateRes(\n",
    "            status=Status(\n",
    "                code=Code.OK,\n",
    "                message=\"OK\",\n",
    "            ),\n",
    "            loss=0.0,\n",
    "            num_examples=num_val,\n",
    "            metrics={\"error\": auc},\n",
    "        )\n",
    "\n",
    "\n",
    "# Start Flower client\n",
    "fl.client.start_client(server_address=\"127.0.0.1:8080\", client=XgbClient().to_client())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
